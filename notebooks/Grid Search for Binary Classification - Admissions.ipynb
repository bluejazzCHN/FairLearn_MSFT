{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for Binary Classification - Admissions\n",
    "\n",
    "In this notebook, we will apply the `GridSearch` algorithm in FairLearn to a binary classification problem, where we also have a binary protected attribute. This algorithm comes from the paper [\"A Reductions Approach to Fair Classification\" (Agarwal et al. 2018)](https://arxiv.org/abs/1803.02453). The grid search is a simplified version of the full algorithm (appearing in section 3.4), which works best for binary classification and a binary protected attribute.\n",
    "\n",
    "The specific problem we consider is a biased college admissions problem. We assume that we have a group of males and females (gender will be our protected attribute), with matching standardised test scores and some other irrelevant feature which is correlated with gender. We also have a set of labels denoting whether or not each individual was admitted, and we will make this (generated) historical data biased, by setting a higher threshold for females than males. We will make the standardised test scores independent of gender, so if admissions were unbiased, both genders would be admitted in equal portions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import GridSearch\n",
    "from fairlearn.reductions import DemographicParity\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Data\n",
    "\n",
    "We are going to synthesise data for this scenario. We will generate a dataset with two features - \"score\" and \"irrelevant.\" Both will be follow a normal distribution, but while the \"score\" feature will be parameterised by a single mean and standard deviation, the \"irrelevant\" feature will be affected by gender. To create the biased historical labels, we will set different thresholds for each gender (with a small around of normally distributed jitter around each threshold).\n",
    "\n",
    "The following class implements this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self):\n",
    "        # We use label and index 0 for female and 1 for male\n",
    "        self.number = [400, 900]\n",
    "        \n",
    "        self.score_mean = 0.5\n",
    "        self.score_std_dev = 0.2\n",
    "        \n",
    "        self.score_threshold = [0.8, 0.5]\n",
    "        self.score_threshold_jitter = [0.02, 0.02]\n",
    "        \n",
    "        self.irrelevant_mean = [0.4, 0.7]\n",
    "        self.irrelevant_std_dev = [0.1, 0.1]\n",
    "        \n",
    "    def generate(self):\n",
    "        genders = []\n",
    "        scores = []\n",
    "        admissions = []\n",
    "        irrelevants = []\n",
    "\n",
    "        for g in range(2):\n",
    "            s, a, ir = self._generate_single_dataset(self.number[g],\n",
    "                                                     self.score_threshold[g],\n",
    "                                                     self.score_threshold_jitter[g],\n",
    "                                                     self.irrelevant_mean[g],\n",
    "                                                     self.irrelevant_std_dev[g])\n",
    "            genders.append(np.full(self.number[g], g))\n",
    "            scores.append(s)\n",
    "            admissions.append(a)\n",
    "            irrelevants.append(ir)\n",
    "        \n",
    "        all_scores = np.concatenate( (scores[0], scores[1]), axis=None)\n",
    "        all_admissions = np.concatenate( (admissions[0], admissions[1]), axis=None)\n",
    "        all_irrelevants = np.concatenate( (irrelevants[0], irrelevants[1]), axis=None)\n",
    "        all_genders = np.concatenate( (genders[0], genders[1]), axis=None)\n",
    "        \n",
    "        A = pd.Series(data=all_genders, name=\"Gender\")\n",
    "        X = pd.DataFrame({\"score\":all_scores,\n",
    "                          \"irrelevant\": all_irrelevants})\n",
    "        Y = pd.Series(data=all_admissions, name=\"Admitted\")\n",
    "        \n",
    "        return X, Y, A\n",
    "        \n",
    "    def _generate_single_dataset(self,\n",
    "                                 number_samples,\n",
    "                                 threshold, threshold_jitter,\n",
    "                                 irr_mean, irr_std_dev):\n",
    "        scores = np.random.normal(loc=self.score_mean,\n",
    "                                  scale=self.score_std_dev,\n",
    "                                  size=number_samples)\n",
    "        scores[ scores < 0 ] = 0\n",
    "        scores[ scores > 1 ] = 1\n",
    "    \n",
    "        threshold = np.random.normal(loc=threshold, scale=threshold_jitter, size=number_samples)\n",
    "        threshold[ threshold < 0 ] = 0\n",
    "        threshold[ threshold > 1 ] = 1\n",
    "    \n",
    "        def admit(s, t): return int(s > t)\n",
    "    \n",
    "        vadmit = np.vectorize(admit)\n",
    "    \n",
    "        admitted = vadmit(scores, threshold)\n",
    "    \n",
    "        irrelevant = np.random.normal(loc=irr_mean, scale=irr_std_dev, size=number_samples)\n",
    "    \n",
    "        return scores, admitted, irrelevant\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use this class to generate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGenerator()\n",
    "\n",
    "X, Y, A = dg.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `matplotlib` to examine some of the data. First we examine the distribution of the data in the `X` feature array. As expected, the \"score\" feature has an identical distribution, but the \"irrelevant\" feature shows a gender difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_width = 8\n",
    "plot_height = 6\n",
    "plt.rcParams[\"figure.figsize\"] = (plot_width, plot_height) # (w, h)\n",
    "\n",
    "# Nice caption text\n",
    "gender_labels = [\"Female\", \"Male\"]\n",
    "\n",
    "# Plot two histograms for the given column\n",
    "def histograms(X_s, A_s, col_name):\n",
    "    \n",
    "    sep_data = [X_s[col_name][A_s==0], X_s[col_name][A_s==1]]\n",
    "    \n",
    "    plt.hist(sep_data, histtype=\"step\", bins=20, label=gender_labels)\n",
    "    plt.xlabel(col_name)\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "histograms(X, A, \"score\")\n",
    "histograms(X, A, \"irrelevant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also examine whether each individual was admitted as a function of their test score. This clearly shows the bias against females:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_admissions_vs_scores(X_s, Y_s, A_s):\n",
    "    markers=[\".\", \"x\"]\n",
    "    for i in range(2):\n",
    "        mask = A_s == i\n",
    "        plt.scatter(X_s[mask].score, Y_s[mask], label=gender_labels[i], marker=markers[i])\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.ylabel(\"Admitted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_admissions_vs_scores(X, Y, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the above data in a slightly different way - as the fraction of each gender admitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_admission_fractions(Y_s, A_s):\n",
    "    f_frac = np.mean(Y_s[A_s==0])\n",
    "    m_frac = np.mean(Y_s[A_s==1])\n",
    "    \n",
    "    plt.bar(x=range(2), height=[f_frac, m_frac], tick_label=gender_labels)\n",
    "    plt.ylabel(\"Admisison Fraction\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_admission_fractions(Y, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data\n",
    "\n",
    "Before training models, we first perform a standard split of the data into 'train' and 'test' subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test, A_train, A_test = train_test_split(X, Y, A,\n",
    "                                                                     test_size = 0.2,\n",
    "                                                                     random_state=0,\n",
    "                                                                     stratify=Y)\n",
    "\n",
    "# Work around indexing bug\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "A_train = A_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "A_test = A_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an Unmitigated Model\n",
    "\n",
    "Before we try mitigating the bias, we can first try training a naive model. For simplicity, we will use the `LogisticRegression` estimator from `sklearn`. Once the model is trained, we can examine the values of the `coef_` array which stores the coefficients of each column from the model - the first corresponds to the \"score\" feature, while the second corresponds to the \"irrelevant\" feature. We can see that there is a non-zero weight on the \"irrelevant\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmitigated_model = LogisticRegression(solver='liblinear', fit_intercept=True)\n",
    "unmitigated_model.fit(X_train, Y_train)\n",
    "\n",
    "unmitigated_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also obtain predictions from this model, and examine them. It's obvious that the bias has been maintained, although it is not quite as dramatic as in the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict_unmitigated = unmitigated_model.predict(X_test)\n",
    "\n",
    "plot_admissions_vs_scores(X_test, Y_predict_unmitigated, A_test)\n",
    "plot_admission_fractions(Y_predict_unmitigated, A_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can examine metrics for this model. `fairlearn` implements group metrics, which apply a given metric function to the entire dataset, and also subgroups within it. First, we can look at the error, as calculated by the `zero_one_loss` function from `sklearn` as wrapped by `fairlearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import group_zero_one_loss\n",
    "\n",
    "unmitigated_error = group_zero_one_loss(Y_test, Y_predict_unmitigated, A_test)\n",
    "print(\"Overall error     {0:.4f}\".format(unmitigated_error.overall))\n",
    "print(\"Error for females {0:.4f}\".format(unmitigated_error.by_group[0]))\n",
    "print(\"Error for males   {0:.4f}\".format(unmitigated_error.by_group[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `group_mean_prediction` metric allows us to see the fraction of each group admitted, as well as the range of admission fractions, which is the disparity in this context. This disparity is what we seek to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import group_mean_prediction\n",
    "\n",
    "unmitigated_mean_prediction = group_mean_prediction(Y_test, Y_predict_unmitigated, A_test)\n",
    "print(\"Overall Admission Rate  {0:.4f}\".format(unmitigated_mean_prediction.overall))\n",
    "print(\"Female Admission Rate   {0:.4f}\".format(unmitigated_mean_prediction.by_group[0]))\n",
    "print(\"Male Admission Rate     {0:.4f}\".format(unmitigated_mean_prediction.by_group[1]))\n",
    "print(\"Disparity in Admissions {0:.4f}\".format(unmitigated_mean_prediction.range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Unfairness with Grid Search\n",
    "\n",
    "Now, we move on to attempting to reduce the unfairness in our model using the grid search. This tries a series of different models, parameterised by a Lagrange multiplier $\\lambda_i$. For each value of $\\lambda$, the algorithm reweights and relabels the input data, and trains a fresh model ($\\lambda=0$ corresponds to the unaltered case).\n",
    "\n",
    "The grid search acts like a normal `sklearn` estimator, implementing `fit()` and `predict()` methods. The `fit()` method performs the grid search, and the best model found (according to a specified selection rule) is used in `predict()` calls. However, after `fit()` is called, there are two extra properties on the estimator - a `best_result` and a list `all_results`; the `best_result` is used by `predict()` while `all_results` corresponds to the output of the grid search itself. The items in each are dictionaries, each with four entries - `lambda_vec`, `objective`, `gamma` and `predictor`.\n",
    "\n",
    "We start by telling the algorithm that we want to try 7 different values of $\\lambda$ (which are generated for us). We specify demographic parity as our constraint - since the distribution of scores is the same for both genders, we should expect that the admission fraction for each should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sweep=GridSearch(LogisticRegression(solver='liblinear', fit_intercept=True),\n",
    "                       constraints=DemographicParity(),\n",
    "                       grid_size=7)\n",
    "\n",
    "first_sweep.fit(X, Y, sensitive_features=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the values of $\\lambda_i$ chosen for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vecs = [x.lambda_vec for x in (first_sweep.all_results)]\n",
    "lambda_vecs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is rather more than a single value $\\lambda$, so what's going on? These results are the outputs of the `Moment` type which drives the reduction approach to removing disparity. There are actually four Lagrange multipliers here, indexed by a tuple (sign, event, group_id). The 'group_id' field corresponds to the labels 0 (for \"female\") and 1 (for \"male\", while the 'grp' field is the same in all cases (this is because we have specified Demographic Parity as our disparity criterion). Finally the 'sign' comes from the reductions approach specifying separate multipliers for violations of the disparity criterion from above and below. Both of these are constrained to be positive.\n",
    "\n",
    "So we have four multipliers - $\\lambda_{(+,0)}$, $\\lambda_{(-,0)}$, $\\lambda_{(+,1)}$ and $\\lambda_{(-,1)}$. Without losing generality, we can decide to modify one of these, but not the other, and the `DemographicParity` object we passed to the `GridSearch` constructor chose to make $\\lambda_{(+,1)}=\\lambda_{(-,1)}=0$. Finally, we can combine the 'above' and 'below' multipliers for the other group and obtain $\\lambda_i = \\lambda_{(+,0)} - \\lambda_{(-,0)}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_multipliers = [x[(\"+\", \"all\", 0)]-x[(\"-\", \"all\", 0)] for x in lambda_vecs]\n",
    "actual_multipliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at how the weight the models place on the protected attribute (recall that in the fair case, this would be zero) varies with $\\lambda_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sweep_irrelevant_weights = [\n",
    "    x.predictor.coef_[0][1] for x in first_sweep.all_results\n",
    "]\n",
    "\n",
    "plt.scatter(actual_multipliers, first_sweep_irrelevant_weights)\n",
    "plt.xlabel(\"Lagrange Multiplier\")\n",
    "plt.ylabel(\"Weight on irrelevant feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GridSearch` object also implements a `predict` method which is routed to the model determined to be the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_first_sweep = first_sweep.predict(X)\n",
    "\n",
    "plot_admissions_vs_scores(X, Y_first_sweep, A)\n",
    "plot_admission_fractions(Y_first_sweep, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the `best_model` on the `GridSearch` object we see that the case where $\\lambda=0$ was the best in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_best = first_sweep.best_result.lambda_vec[(\"+\", \"all\", 0)]-first_sweep.best_result.lambda_vec[(\"-\", \"all\", 0)]\n",
    "print(\"lambda_best = \", lambda_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a Second Sweep\n",
    "\n",
    "We can generate our own set of $\\lambda$ values based on the best one before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_sweep_multipliers = np.linspace(lambda_best-0.5, lambda_best+0.5, 31)\n",
    "\n",
    "iterables = [['+', '-'], ['all'], [0, 1]]\n",
    "midx = pd.MultiIndex.from_product(iterables, names=['sign', 'event', 'group_id'])\n",
    "\n",
    "second_sweep_lambdas = []\n",
    "for l in second_sweep_multipliers:\n",
    "    nxt = pd.Series(np.zeros(4), index=midx)\n",
    "    if l < 0:\n",
    "        nxt[(\"-\", \"all\", 0)] = abs(l)\n",
    "    else:\n",
    "        nxt[(\"+\", \"all\", 0)] = l\n",
    "    second_sweep_lambdas.append(nxt)\n",
    "    \n",
    "multiplier_df = pd.concat(second_sweep_lambdas,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use these multipliers in a new `GridSearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_sweep=GridSearch(LogisticRegression(solver='liblinear', fit_intercept=True),\n",
    "                        constraints=DemographicParity(),\n",
    "                        grid=multiplier_df)\n",
    "\n",
    "second_sweep.fit(X, Y, sensitive_features=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the weight placed on the \"irrelevant\" feature as a function of $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_sweep_irrelevant_weights = [\n",
    "    x.predictor.coef_[0][1] for x in second_sweep.all_results\n",
    "]\n",
    "\n",
    "plt.scatter(second_sweep_multipliers, second_sweep_irrelevant_weights)\n",
    "plt.xlabel(\"Lagrange Multiplier\")\n",
    "plt.ylabel(\"Weight on irrelevant feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the weight on the irrelevant feature between the best model here and the original unmitigated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weight on irrelevant feature in unmitigated model\", unmitigated_model.coef_[0][1])\n",
    "print(\"Weight on irrelevant feature in best model\", second_sweep.best_result.predictor.coef_[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can obtain the new predictions. We see that we have almost equalised the admissions rate, as we would expect for a constraint of demographic parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_second_sweep = second_sweep.predict(X)\n",
    "\n",
    "plot_admissions_vs_scores(X, Y_second_sweep, A)\n",
    "plot_admission_fractions(Y_second_sweep, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
