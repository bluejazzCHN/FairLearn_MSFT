{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for Binary Classification - Admissions\n",
    "\n",
    "In this notebook, we will apply the `GridSearch` algorithm in FairLearn to a binary classification problem, where we also have a binary protected attribute. This algorithm comes from the paper [\"A Reductions Approach to Fair Classification\" (Agarwal et al. 2018)](https://arxiv.org/abs/1803.02453). The grid search is a simplified version of the full algorithm (appearing in section 3.4), which works best for binary classification and a binary protected attribute.\n",
    "\n",
    "The specific problem we consider is a biased college admissions problem. We assume that we have a group of males and females (gender will be our protected attribute), with matching standardised test scores and some other irrelevant feature which is correlated with gender. We also have a set of labels denoting whether or not each individual was admitted, and we will make this (generated) historical data biased, by setting a higher threshold for females than males. We will make the standardised test scores independent of gender, so if admissions were unbiased, both genders would be admitted in equal portions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import GridSearch\n",
    "from fairlearn.reductions import DemographicParity\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Data\n",
    "\n",
    "We are going to synthesise data for this scenario. We will generate a dataset with two features - \"score\" and \"irrelevant.\" Both will be follow a normal distribution, but while the \"score\" feature will be parameterised by a single mean and standard deviation, the \"irrelevant\" feature will be affected by gender. Similarly in the biased historical data, we will set different thresholds for the two genders (with a small around of normally distributed jitter around each threshold).\n",
    "\n",
    "The following class implements this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self):\n",
    "        # We use label and index 0 for female and 1 for male\n",
    "        self.number = [100, 300]\n",
    "        \n",
    "        self.score_mean = 0.5\n",
    "        self.score_std_dev = 0.1\n",
    "        \n",
    "        self.score_threshold = [0.6, 0.4]\n",
    "        self.score_threshold_jitter = [0.05, 0.05]\n",
    "        \n",
    "        self.irrelevant_mean = [0.3, 0.7]\n",
    "        self.irrelevant_std_dev = [0.2, 0.2]\n",
    "        \n",
    "    def generate(self):\n",
    "        genders = []\n",
    "        scores = []\n",
    "        admissions = []\n",
    "        irrelevants = []\n",
    "\n",
    "        for g in range(2):\n",
    "            s, a, ir = self._generate_single_dataset(self.number[g],\n",
    "                                                     self.score_threshold[g],\n",
    "                                                     self.score_threshold_jitter[g],\n",
    "                                                     self.irrelevant_mean[g],\n",
    "                                                     self.irrelevant_std_dev[g])\n",
    "            genders.append(np.full(self.number[g], g))\n",
    "            scores.append(s)\n",
    "            admissions.append(a)\n",
    "            irrelevants.append(ir)\n",
    "        \n",
    "        all_scores = np.concatenate( (scores[0], scores[1]), axis=None)\n",
    "        all_admissions = np.concatenate( (admissions[0], admissions[1]), axis=None)\n",
    "        all_irrelevants = np.concatenate( (irrelevants[0], irrelevants[1]), axis=None)\n",
    "        all_genders = np.concatenate( (genders[0], genders[1]), axis=None)\n",
    "        \n",
    "        A = pd.Series(data=all_genders, name=\"Gender\")\n",
    "        X = pd.DataFrame({\"score\":all_scores,\n",
    "                          \"irrelevant\": all_irrelevants})\n",
    "        Y = pd.Series(data=all_admissions, name=\"Admitted\")\n",
    "        \n",
    "        return X, Y, A\n",
    "        \n",
    "    def _generate_single_dataset(self,\n",
    "                                 number_samples,\n",
    "                                 threshold, threshold_jitter,\n",
    "                                 irr_mean, irr_std_dev):\n",
    "        scores = np.random.normal(loc=self.score_mean,\n",
    "                                  scale=self.score_std_dev,\n",
    "                                  size=number_samples)\n",
    "        scores[ scores < 0 ] = 0\n",
    "        scores[ scores > 1 ] = 1\n",
    "    \n",
    "        threshold = np.random.normal(loc=threshold, scale=threshold_jitter, size=number_samples)\n",
    "        threshold[ threshold < 0 ] = 0\n",
    "        threshold[ threshold > 1 ] = 1\n",
    "    \n",
    "        def admit(s, t): return int(s > t)\n",
    "    \n",
    "        vadmit = np.vectorize(admit)\n",
    "    \n",
    "        admitted = vadmit(scores, threshold)\n",
    "    \n",
    "        irrelevant = np.random.normal(loc=irr_mean, scale=irr_std_dev, size=number_samples)\n",
    "    \n",
    "        return scores, admitted, irrelevant\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use this class to generate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGenerator()\n",
    "\n",
    "X, Y, A = dg.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `matplotlib` to examine some of the data. First we examine the distribution of the data in the `X` feature array. As expected, the \"score\" feature has an identical distribution, but the \"irrelevant\" feature shows a gender difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_width = 12\n",
    "plot_height = 8\n",
    "plt.rcParams[\"figure.figsize\"] = (plot_width, plot_height) # (w, h)\n",
    "\n",
    "# Nice caption text\n",
    "gender_labels = [\"Female\", \"Male\"]\n",
    "\n",
    "# Plot two histograms for the given column\n",
    "def histograms(X_s, A_s, col_name):\n",
    "    \n",
    "    sep_data = [X_s[col_name][A_s==0], X_s[col_name][A_s==1]]\n",
    "    \n",
    "    plt.hist(sep_data, histtype=\"step\", bins=20, label=gender_labels)\n",
    "    plt.xlabel(col_name)\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "histograms(X, A, \"score\")\n",
    "histograms(X, A, \"irrelevant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also examine whether each individual was admitted as a function of their test score. This clearly shows the bias against females:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_admissions_vs_scores(X_s, Y_s, A_s):\n",
    "    markers=[\".\", \"x\"]\n",
    "    for i in range(2):\n",
    "        mask = A_s == i\n",
    "        plt.scatter(X_s[mask].score, Y_s[mask], label=gender_labels[i], marker=markers[i])\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.ylabel(\"Admitted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_admissions_vs_scores(X, Y, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
